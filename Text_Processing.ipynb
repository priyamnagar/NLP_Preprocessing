{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Procecssing\n",
    "## Capturing text data\n",
    "### Plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would love to try or hear the sample audio your app can produce. I do not want to purchase, because I've purchased so many apps that say they do something and do not deliver.  \n",
      "\n",
      "Can you please add audio samples with text you've converted? I'd love to see the end results.\n",
      "\n",
      "Thanks!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text=''\n",
    "with open('text.txt','r') as f:\n",
    "    text = f.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Date</th>\n",
       "      <th>End Time</th>\n",
       "      <th>Event Title</th>\n",
       "      <th>All Day Event</th>\n",
       "      <th>No End Time</th>\n",
       "      <th>Event Description</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Contact Email</th>\n",
       "      <th>Contact Phone</th>\n",
       "      <th>Location</th>\n",
       "      <th>Category</th>\n",
       "      <th>Mandatory</th>\n",
       "      <th>Registration</th>\n",
       "      <th>Maximum</th>\n",
       "      <th>Last Date To Register</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>3:00:00 PM</td>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Studies Dept. Meeting</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Department meeting</td>\n",
       "      <td>Chris Gallagher</td>\n",
       "      <td>cgallagher@schoolwires.com</td>\n",
       "      <td>814-555-5179</td>\n",
       "      <td>High School</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>9/2/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>6:00:00 PM</td>\n",
       "      <td>9/5/2011</td>\n",
       "      <td>8:00:00 PM</td>\n",
       "      <td>Curriculum Meeting</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Curriculum Meeting</td>\n",
       "      <td>Chris Gallagher</td>\n",
       "      <td>cgallagher@schoolwires.com</td>\n",
       "      <td>814-555-5179</td>\n",
       "      <td>High School</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "      <td>9/2/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Start Date   Start Time  End Date    End Time                  Event Title   \\\n",
       "0    9/5/2011  3:00:00 PM  9/5/2011         NaN  Social Studies Dept. Meeting   \n",
       "1    9/5/2011  6:00:00 PM  9/5/2011  8:00:00 PM            Curriculum Meeting   \n",
       "\n",
       "  All Day Event No End Time   Event Description         Contact   \\\n",
       "0             N           Y  Department meeting  Chris Gallagher   \n",
       "1             N           N  Curriculum Meeting  Chris Gallagher   \n",
       "\n",
       "                Contact Email Contact Phone     Location  Category Mandatory  \\\n",
       "0  cgallagher@schoolwires.com  814-555-5179  High School         2         N   \n",
       "1  cgallagher@schoolwires.com  814-555-5179  High School         2         N   \n",
       "\n",
       "  Registration  Maximum Last Date To Register  \n",
       "0            N       25              9/2/2011  \n",
       "1            N       25              9/2/2011  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tabular.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': {'total': 1}, 'contents': {'quotes': [{'quote': 'I know for sure that what we dwell on is who we become.', 'author': 'Oprah Winfrey', 'length': '55', 'tags': ['dwell', 'inspire', 'motivational'], 'category': 'inspire', 'title': 'Inspiring Quote of the day', 'date': '2019-05-20', 'id': None}], 'copyright': '2017-19 theysaidso.com'}}\n"
     ]
    }
   ],
   "source": [
    "r=requests.get('https://quotes.rest/qod.json')\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I would love to try or hear the sample audio your app can produce. I do not want to purchase, because I've purchased so many apps that say they do something and do not deliver.  \\n\\nCan you please add audio samples with text you've converted? I'd love to see the end results.\\n\\nThanks!\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I would love to try or hear the sample audio your app can produce. I do not want to purchase, because I've purchased so many apps that say they do something and do not deliver. Can you please add audio samples with text you've converted? I'd love to see the end results. Thanks! \""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = re.sub(' +',' ',text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Normalization\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Punctuation removal\n",
    "text = re.sub(r'[^a-zA-Z0-9]',\" \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would love to try or hear the sample audio your app can produce  i do not want to purchase  because i ve purchased so many apps that say they do something and do not deliver  can you please add audio samples with text you ve converted  i d love to see the end results  thanks  \n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'would', 'love', 'to', 'try', 'or', 'hear', 'the', 'sample', 'audio', 'your', 'app', 'can', 'produce', 'i', 'do', 'not', 'want', 'to', 'purchase', 'because', 'i', 've', 'purchased', 'so', 'many', 'apps', 'that', 'say', 'they', 'do', 'something', 'and', 'do', 'not', 'deliver', 'can', 'you', 'please', 'add', 'audio', 'samples', 'with', 'text', 'you', 've', 'converted', 'i', 'd', 'love', 'to', 'see', 'the', 'end', 'results', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [w for w in tokens if w not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['would', 'love', 'try', 'hear', 'sample', 'audio', 'app', 'produce', 'want', 'purchase', 'purchased', 'many', 'apps', 'say', 'something', 'deliver', 'please', 'add', 'audio', 'samples', 'text', 'converted', 'love', 'see', 'end', 'results', 'thanks']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('would', 'MD'), ('love', 'VB'), ('try', 'NN'), ('hear', 'JJ'), ('sample', 'JJ'), ('audio', 'JJ'), ('app', 'NN'), ('produce', 'NN'), ('want', 'VBP'), ('purchase', 'NN'), ('purchased', 'VBD'), ('many', 'JJ'), ('apps', 'NNS'), ('say', 'VBP'), ('something', 'NN'), ('deliver', 'JJ'), ('please', 'NN'), ('add', 'VB'), ('audio', 'JJ'), ('samples', 'NNS'), ('text', 'RB'), ('converted', 'VBN'), ('love', 'NN'), ('see', 'VBP'), ('end', 'JJ'), ('results', 'NNS'), ('thanks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-94-aa0714ea46d4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-94-aa0714ea46d4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tokens1 = [PorterStemmer()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "tokens1 = [PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-388cde72d279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokens1' is not defined"
     ]
    }
   ],
   "source": [
    "print(tokens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = [WordNetLemmatizer().lemmatize(w) for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['would', 'love', 'tri', 'hear', 'sampl', 'audio', 'app', 'produc', 'want', 'purchas', 'purchas', 'mani', 'app', 'say', 'someth', 'deliv', 'plea', 'add', 'audio', 'sampl', 'text', 'convert', 'love', 'see', 'end', 'result', 'thank']\n"
     ]
    }
   ],
   "source": [
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
